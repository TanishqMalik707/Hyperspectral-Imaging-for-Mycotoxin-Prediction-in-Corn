{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7d9657-42b6-4ab8-8a30-a30799e33ee6",
   "metadata": {},
   "source": [
    "## We will try training different model and compare their perfomance using Expirement tracking in ML FLOW and we will include only the code of the model which performs better and the log file and video comparison of all the models is in github repo which shows ML FLOW UI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0183a04-8014-4ba5-ba60-4885d0147bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/11 02:01:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, Scaler, and Selected Features saved successfully!\n",
      "CV MAE: 1.9350276179633414\n",
      "CV MSE: 6.545835174345885\n",
      "CV R2 Score: 0.22038883967208775\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"TASK2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "df.drop(columns=['hsi_id'], inplace=True)\n",
    "X = df.drop(columns=['vomitoxin_ppb'])\n",
    "y = df['vomitoxin_ppb']\n",
    "\n",
    "# Outlier Detection and Removal\n",
    "def remove_outliers_iqr(df, columns, threshold=1.5):\n",
    "    \"\"\"Removes outliers using the IQR method.\"\"\"\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "X_no_outliers = remove_outliers_iqr(X, X.columns)\n",
    "y_no_outliers = y[X_no_outliers.index]\n",
    "\n",
    "# Scale the spectral data\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_no_outliers)\n",
    "\n",
    "# Log-transform the target variable\n",
    "y_transformed = np.log1p(y_no_outliers)\n",
    "\n",
    "# Feature Selection using Random Forest\n",
    "rf_temp = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_temp.fit(X_scaled, y_transformed)\n",
    "feature_importances = rf_temp.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_no_outliers.columns, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "selected_features = feature_importance_df['Feature'].head(50).tolist()\n",
    "X_selected = X_scaled[:, [X_no_outliers.columns.get_loc(col) for col in selected_features]]\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=kf,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_selected, y_transformed)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-Validation with Best Model\n",
    "scores_mae = cross_val_score(best_rf_model, X_selected, y_transformed, cv=kf, scoring='neg_mean_absolute_error')\n",
    "scores_mse = cross_val_score(best_rf_model, X_selected, y_transformed, cv=kf, scoring='neg_mean_squared_error')\n",
    "scores_r2 = cross_val_score(best_rf_model, X_selected, y_transformed, cv=kf, scoring='r2')\n",
    "\n",
    "mean_mae = -scores_mae.mean()\n",
    "mean_mse = -scores_mse.mean()\n",
    "mean_r2 = scores_r2.mean()\n",
    "\n",
    "# Start MLflow Experiment\n",
    "with mlflow.start_run(run_name=\"Random_Forest_Outlier_FS_Tune_Log_Transform\"):\n",
    "    mlflow.log_metric(\"CV_MAE\", mean_mae)\n",
    "    mlflow.log_metric(\"CV_MSE\", mean_mse)\n",
    "    mlflow.log_metric(\"CV_R2\", mean_r2)\n",
    "    mlflow.sklearn.log_model(best_rf_model, \"Random_Forest_Outlier_FS_Tune_Log_Transform\")\n",
    "\n",
    "# Save Model and Preprocessing Artifacts\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(selected_features, \"selected_features.pkl\")\n",
    "mlflow.sklearn.save_model(best_rf_model, \"rf_model\")\n",
    "\n",
    "print(\"Model, Scaler, and Selected Features saved successfully!\")\n",
    "print(f\"CV MAE: {mean_mae}\")\n",
    "print(f\"CV MSE: {mean_mse}\")\n",
    "print(f\"CV R2 Score: {mean_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a49742-aefb-4288-bb5b-5372b8f7358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is B294-F0F6\n",
      "\n",
      " Directory of C:\\Users\\tanishq\\mlruns\n",
      "\n",
      "03/10/2025  09:48 PM    <DIR>          .\n",
      "03/10/2025  09:48 PM    <DIR>          ..\n",
      "03/10/2025  09:43 PM    <DIR>          .trash\n",
      "03/11/2025  02:01 AM    <DIR>          0\n",
      "03/10/2025  09:48 PM    <DIR>          models\n",
      "               0 File(s)              0 bytes\n",
      "               5 Dir(s)  38,051,876,864 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls mlruns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17a0fa1-b0fd-4aa4-a2e3-938d71510415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['mlflow', 'ui']>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.Popen([\"mlflow\", \"ui\"], shell=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff50ab-8a6b-4a7b-b329-26f7fae8d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m mlflow ui --port 5000 --host 127.0.0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba2f58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77aad66e",
   "metadata": {},
   "source": [
    "# Observations on Model Performance\n",
    "## Despite applying outlier removal, feature selection, and hyperparameter tuning, the modelâ€™s performance did not improve significantly. This could be due to the limited dataset size (500 samples), high dimensionality (450 features), and potential noise in the data. Further improvements may require more data collection, advanced feature extraction, or deep learning approaches. This notebook documents the best possible efforts to optimize performance given the dataset constraints."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
